---
title: "DNN biology evaluation"
author: "Carlos Ruiz"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Introduction

In this document, we compared the features generated by the DNN models in a whole blood dataset of two rare diseases (Kabuki and CHARGE). We designed the DNN using biological information. Thus, the first layer contained neurons connected to CpGs mapped to the same gene. In addition, we included additional neurons in this layer mapped to Cpgs from the same chromosome to account for other patterns. This first layer was followed by two dense networks that lead to a classifier. 

```{r}
library(HDF5Array)
library(SummarizedExperiment)
library(tidyverse)
library(limma)
library(pheatmap)
library(e1071)
library(meffil)
```

# Initial dataset

## Descriptives

```{r}
se <- loadHDF5SummarizedExperiment("../data/GSE97362/", prefix = "GSE97362_raw")
se$disease <- factor(se$`disease state:ch1`, levels = c("Control", "CHARGE", "Kabuki",  "CHD7 variant","KMT2D variant"))
se$sex <- ifelse(se$characteristics_ch1 == "gender: female", "female", "male")
se$age <- as.numeric(gsub("age (years): ", "", se$characteristics_ch1.1, fixed = TRUE ))

discov <- se[, ! se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
val <- se[, se$`sample type:ch1` %in% c("Control for validation cohort",  "Validation cohort") ]
```

Our initial dataset contained `r ncol(se)` individuals and `r nrow(se)` CpGs. Of the `r ncol(se)` samples, `r sum(se$disease == "Control")` were controls, `r sum(se$disease == "CHARGE")` had CHARGE while\
`r sum(se$disease == "Kabuki")` had Kabuki. The remaining individuals had variants candidate of causing one of the diseases. We also have `r sum(se$sex == "male")` boys and `r sum(se$sex == "female")` girls.

## Overall pattern

We first explored whether there were clusters of samples with distinctive global methylation patterns. To test this, we run a PCA on this data. We only included the 40K CpGs with highest variance:

```{r}
pc_ini <- meffil.methylation.pcs(data.matrix(assay(se)), probe.range = 40000) %>%
  data.frame()
pc_ini$disease <- colData(se)[rownames(pc_ini), "disease"]
pc_ini$sex <- colData(se)[rownames(pc_ini), "sex"]
pc_ini %>% 
  ggplot(aes(x = PC1, y = PC2, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("All CpGs - Disease")

```

Some individuals have different methylation patterns in the PC2. These differences seem to be related with disease status. Therefore, we explored other principal components:

```{r}
pc_ini %>% 
  ggplot(aes(x = PC3, y = PC4, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("All CpGs - Disease")

pc_ini %>% 
  ggplot(aes(x = PC2, y = PC4, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("All CpGs - Disease")

```

We also observed some differences due to disease in PC4. When combining PC2 and PC4, we observed that PC2 differentiates CHARGE (and CHD7 variants, variants suspected of causing CHARGE) from control samples, while PC4 differentiates control samples from Kabuki (and KMT2D variants).

```{r}
pc_ini %>% 
  ggplot(aes(x = PC1, y = PC2, color = sex)) +
  geom_point() + 
  theme_bw() +
  ggtitle("All CpGs - Sex")
```

We do not observe difference between boys and girls in the first 2 PCs. Thus, the patterns of sex are weaker than the patterns of the disease.

## Application of state-of-the-art method

Before going to the CNN models, we will test how the current state-of-the-art method works in this dataset. Briefly, the current method has two steps:

1.  Define the CpGs with more different methylation values between cases and controls
2.  Use these CpGs to train a SVM model.

In the original paper, the authors had a set of samples with known disease status (labelled as CHARGE or Kabuki), and another set with suspicious variants (CHD7 or KMT2D variants). They trained the model in the samples with known status and applied it to the samples with suspicious variants. We will use the same data division.

Thus, we will use samples with known status to define the set of CpGs differentiating cases from controls and then train the SVM. We will select probes with an adjusted p-value \< 0.01 and a FC \> 0.1 (in absolute value).

### Feature selection

```{r}

diseases <- c("CHARGE", "Kabuki")
names(diseases) <- c("CHARGE", "Kabuki")

getFeatures <- function(set, disease, minFC = 0.1){
  
  set <- set[, set$disease %in% c("Control", disease)]
  set$disease <- droplevels(set$disease)
  model <- model.matrix(~ disease + sex + age, colData(set))
  
  lmF <- lmFit(assay(set[, rownames(model)]), model)
  lmFe <- eBayes(lmF)
  tabA <- topTable(lmFe, coef = 2, n = Inf)
  selTab <- subset(tabA, !is.na(logFC) & adj.P.Val < 0.01 & abs(logFC) > minFC)
  selCpGs <- rownames(selTab)
  
}
sel_cpgs <- lapply(diseases, getFeatures, set = discov)
sel_cpgs_vec <- unique(unlist(sel_cpgs))
```

A total of `r length(sel_cpgs$CHARGE)` and `r length(sel_cpgs$Kabuki)` CpGs had different methylation values in controls than in CHARGE or Kabuki, respectively.

```{r}
col_colors <- list(
  disease = c("Control" = "black", "CHARGE" = "green", "Kabuki" = "blue",
              "CHD7 variant" = "lightgreen", "KMT2D variant" = "cyan"),
  sex = c("female" = "purple", "male" = "lightblue")
)

pheatmap(assay(discov)[sel_cpgs_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(discov)[, "disease", drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

The heatmap shows that when including only these selected CpGs, control and case samples are clearly separated in the discovery dataset (dataset used for defining the CpGs). Nonetheless, we observe that CHARGE individuals are separated in two groups, with some samples more similar to control samples.

```{r}
pheatmap(assay(val)[sel_cpgs_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(val)[, "disease", drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)
```

When selecting the same CpGs in the validation dataset, we observe that samples with variants are separeted from controls. In addition, samples with CHD7 variants are separated from samples with KMT2D variants.

### SVM training

```{r}
trainSVM <-  function(set, feats){
  mat <- data.matrix(assay(set[feats, ]))
  imp_mat <- meffil:::impute.matrix(mat, margin = 1, fun = function(x) median(x, na.rm = T))
  
  df <- data.frame(pathClass = factor(set$disease), t(imp_mat))
  model_svm <- svm(pathClass ~ ., df)
}
svm_cpgs <- trainSVM(set = discov, feats = sel_cpgs_vec)

all_mat <- data.matrix(t(assay(se[sel_cpgs_vec, ])))
imp_mat <- meffil:::impute.matrix(all_mat, margin = 2, fun = function(x) median(x, na.rm = T))

pred_cpgs <- predict(svm_cpgs, imp_mat)
table(pred_cpgs, se$disease)

```

The SVM model achieved a very high accuracy. Only one control samples was mislabelled and identified as CHARGE. From the individuals with candidate pathogenic variants, all but 3 were classified under their right disease. 3 individuals with CHD7 variant were classified as control, but we cannot state whether they are a classification error or whether these individuals do not have the pathogenic methylation pattern.


# Dataset passed to network

## Descriptives

We explored whether we obtained the same results with the data after preprocessing for applying CNN model. 

```{r}
se_filt <- loadHDF5SummarizedExperiment("../results/preprocess/GSE97362_DNN/2021-11-16/", prefix = "GSE97362_DNNmissingSub_inputProbes_")
se_filt$disease <- factor(se_filt$`disease state:ch1`, levels = c("Control", "CHARGE", "Kabuki",  "CHD7 variant","KMT2D variant"))
se_filt$sex <- ifelse(se_filt$characteristics_ch1 == "gender: female", "female", "male")
se_filt$age <- as.numeric(gsub("age (years): ", "", se_filt$characteristics_ch1.1, fixed = TRUE ))

discov_filt <- se_filt[, ! se_filt$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
val_filt <- se_filt[, se_filt$`sample type:ch1` %in% c("Control for validation cohort",  "Validation cohort") ]
```

Our initial dataset contained `r ncol(se_filt)` individuals and `r nrow(se_filt)` CpGs. 

## Overall pattern

We first explored whether there were clusters of samples with distinctive global methylation patterns. To test this, we run a PCA on this data. We only included the 40K CpGs with highest variance:

```{r}
pc_ini_filt <- meffil.methylation.pcs(data.matrix(assay(se_filt)), probe.range = 40000) %>%
  data.frame()
pc_ini_filt$disease <- colData(se)[rownames(pc_ini_filt), "disease"]
pc_ini_filt$sex <- colData(se)[rownames(pc_ini_filt), "sex"]
pc_ini_filt %>% 
  ggplot(aes(x = PC1, y = PC2, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("Input CpGs model - Disease")

```

We observe some differences in the second PC.


```{r}
#lapply(1:10, function(i) summary(lm(formula(paste0("PC", i, "~ disease")), pc_ini_filt)) )
pc_ini_filt %>% 
  ggplot(aes(x = PC2, y = PC4, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("Input CpGs model - Disease")

```

We also observed some differences due to disease in PC2 and PC4. With these two components, we can differentiate some cases from controls.

```{r}
pc_ini_filt %>% 
  ggplot(aes(x = PC1, y = PC2, color = sex)) +
  geom_point() + 
  theme_bw() +
  ggtitle("Input CpGs model  - Sex")
```

We do not observe difference between boys and girls in the first 2 PCs. Thus, the patterns of sex are weaker than the patterns of the disease.

### Feature selection

```{r}
sel_cpgs_filt <- lapply(diseases, getFeatures, set = discov_filt)
sel_cpgs_filt_vec <- unique(unlist(sel_cpgs_filt))
```

A total of `r length(sel_cpgs_filt$CHARGE)` and `r length(sel_cpgs_filt$Kabuki)` CpGs had different methylation values in controls than in CHARGE or Kabuki, respectively. Some CpGs previously reported have been lost during pre-processing.

```{r}
pheatmap(assay(discov_filt)[sel_cpgs_filt_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(discov_filt)[, "disease", drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

The heatmap shows that when including only these selected CpGs, control and case samples are clearly separated in the discovery dataset (dataset used for defining the CpGs). Nonetheless, we case samples are split in different groups.

```{r}
pheatmap(assay(val_filt)[sel_cpgs_filt_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(val_filt)[, "disease", drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)
```

When selecting the same CpGs in the validation dataset, we observe that samples with variants are separeted from controls. In addition, samples with CHD7 variants are separated from samples with KMT2D variants.

### SVM training

```{r}
svm_cpgs_filt <- trainSVM(set = discov_filt, feats = sel_cpgs_filt_vec)
pred_cpgs_filt <- predict(svm_cpgs_filt, t(assay(se_filt[sel_cpgs_filt_vec, ])))
table(pred_cpgs_filt, se_filt$disease)

```

After preprocessing, one control sample was classified as CHARGE. For the rest, we acheived a high accuracy. Therefore, the preprocessing is not affecting the signal.

# DNN model

## Description

We train a DNN model in TCGA whose goal was to classify samples into their tumor subtype, including all control tissues as one category. The input contained 9813 samples (80% training/20% test) and the 394,363 CpGs with variability in TCGA. Then, the model had the following layers:


## First layer

This layer contains the results from the different genes and groups of CpGs from the same chromosome.

### General pattern

We first evaluated whether the output of the first layer still contained signal to differentiate the individuals by disease.

```{r}
dnn1_conc <- read_delim("../results/GSE97362_DNN/2021-11-16/model_features/v1/concatenate.tsv", delim = "\t")
dnn1_conc <- data.matrix(dnn1_conc)

dnn1_conc_se <- SummarizedExperiment(t(dnn1_conc), colData = colData(se))
rownames(dnn1_conc_se) <- paste0("Features", seq_len(nrow(dnn1_conc_se)))

discov_dnn1_conc <- dnn1_conc_se[, ! dnn1_conc_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
valid_dnn1_conc <- dnn1_conc_se[, dnn1_conc_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
```

We obtained `r nrow(dnn1_conc_se)` features from the CNN layer. Of those, `r sum(!apply(dnn1_conc, 2, function(x) all(x == 0)))` had values different than 0 in at least a sample.

```{r}
pc_dnn1_conc <- prcomp(dnn1_conc)$x %>%
  data.frame()
rownames(pc_dnn1_conc) <- colnames(dnn1_conc_se)
pc_dnn1_conc$disease <- colData(se)[rownames(pc_dnn1_conc), "disease"]
pc_dnn1_conc$sex <- colData(se)[rownames(pc_dnn1_conc), "sex"]
```

```{r}
pc_dnn1_conc %>% 
  ggplot(aes(x = PC1, y = PC2, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("DNN model layer 1 features - Disease")
```

The top 2 PCs of layer 1 features from DNN model does not allow differentiating the cases from the the control individuals.

```{r}
pc_dnn1_conc %>% 
  ggplot(aes(x = PC3, y = PC5, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("DNN model layer 1 features - Disease")
```

Components PC3 and PC5 of layer 1 features from DNN model  separate samples by disease type. 

```{r}
pc_dnn1_conc %>% 
  ggplot(aes(x = PC1, y = PC2, color = sex)) +
  geom_point() + 
  theme_bw() +
  ggtitle("DNN model layer 1 features - Disease")
```

The first component clearly cluster samples by sex.

Summary: the features computed by the first layer in hte DNN model are capturing the difference in methylation due to sex in the first component, and the differences due to the disease in the second.

### Features selection

```{r}
sel_dnn1_conc <- lapply(diseases, getFeatures, set = discov_dnn1_conc, minFC = 0.05)
sel_dnn1_conc_vec <- unique(unlist(sel_dnn1_conc))
```

A total of `r length(sel_dnn1_conc$CHARGE)` and `r length(sel_dnn1_conc$Kabuki)` features had different methylation values in controls than in CHARGE or Kabuki, respectively.

```{r}
pheatmap(assay(discov_dnn1_conc)[sel_dnn1_conc_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(discov_dnn1_conc)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

Kabuki and control samples are clearly separated. 

```{r}
pheatmap(assay(valid_dnn1_conc)[sel_dnn1_conc_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(valid_dnn1_conc)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)
```

Individuals are clustered by sex and then by disease.

### SVM training

```{r}
svm_dnn1_conc <- trainSVM(set = discov_dnn1_conc, feats = sel_dnn1_conc_vec)

pred_dnn1_conc <- predict(svm_dnn1_conc, t(assay(dnn1_conc_se)))
table(pred_dnn1_conc, se$disease)

```

With this data, the SVM model presented a lower accuracy. Now, it missclassified 7 controls individuals from the training dataset, identified as cases. The classification of suspicious variants had more individuals classified as controls. Nonetheless, these results are more concordant with those published in the original paper.

Summary: The first layer of the DNN network have reduced the differences between the different disease group but it is still sufficient to classify the individuals.

## Dense layer 1 output

### General pattern

We evaluated whether the output of the dense 1 layer still contained signal to differentiate the individuals by disease.

```{r}
dnn1_dense1 <- read_delim("../results/GSE97362_DNN/2021-11-16/model_features/v1/dense.tsv", delim = "\t")
dnn1_dense1 <- data.matrix(dnn1_dense1)

dnn1_dense1_se <- SummarizedExperiment(t(dnn1_dense1), colData = colData(se))
rownames(dnn1_dense1_se) <- paste0("Features", seq_len(nrow(dnn1_dense1_se)))

discov_dnn1_dense1 <- dnn1_dense1_se[, ! dnn1_dense1_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
valid_dnn1_dense1 <- dnn1_dense1_se[, dnn1_dense1_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
```

We obtained `r nrow(dnn1_dense1_se)` features from the dense layer. Of those, `r sum(!apply(dnn1_dense1, 2, function(x) all(x == 0)))` had values different than 0 in at least a sample.

```{r}
pc_dnn1_dense1 <- prcomp(dnn1_dense1)$x %>%
  data.frame()
rownames(pc_dnn1_dense1) <- colnames(dnn1_dense1_se)
pc_dnn1_dense1$disease <- colData(se)[rownames(pc_dnn1_dense1), "disease"]
pc_dnn1_dense1$sex <- colData(se)[rownames(pc_dnn1_dense1), "sex"]
```

```{r}
pc_dnn1_dense1 %>% 
  ggplot(aes(x = PC1, y = PC2, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("DNN1 model dense1 features - Disease")
```

The PC2 of the dense layer 1 of the DNN model differentiates control from CHARGE.

```{r}
pc_dnn1_dense1 %>% 
  ggplot(aes(x = PC2, y = PC3, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("DNN1 model dense1 features - Disease")
```

Components PC2 and PC3 of features from CNN model dense1 cluster samples by disease type. Nonetheless, the clustering was better when using the all the CpGs or the layer 1 features.

```{r}
pc_dnn1_dense1 %>% 
  ggplot(aes(x = PC1, y = PC2, color = sex)) +
  geom_point() + 
  theme_bw() +
  ggtitle("CNN model dense1 features - Sex")
```

The first component is not separating sample by sex. 

Summary: the features computed by the DNN model dense1 layer are capturing the difference in methylation due to disease rather than to sex.

### Features selection

Due to the high number of features without significant values, we remove them before selecting the features.

```{r}
sel_dnn1_dense1 <- lapply(diseases, getFeatures, set = discov_dnn1_dense1[!apply(dnn1_dense1, 2, function(x) all(x == 0)), ], minFC = 0)
sel_dnn1_dense1_vec <- unique(unlist(sel_dnn1_dense1))
```

A total of `r length(sel_dnn1_dense1$CHARGE)` and `r length(sel_dnn1_dense1$Kabuki)` features had different methylation values in controls than in CHARGE or Kabuki, respectively.

```{r}
pheatmap(assay(discov_dnn1_dense1)[sel_dnn1_dense1_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(discov_dnn1_dense1)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

Cases and controls are merged. 

```{r}
pheatmap(assay(valid_dnn1_dense1)[sel_dnn1_dense1_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(valid_dnn1_dense1)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

Some sample with variants are clearly separated from controls.

### SVM model

We repeated the SVM with the features selected in the previous step.

```{r}
svm_dnn1_dense1 <- trainSVM(set = discov_dnn1_dense1, feats = sel_dnn1_dense1_vec)

pred_dnn1_dense1 <- predict(svm_dnn1_dense1, t(assay(dnn1_dense1_se)))
table(pred_dnn1_dense1, se$disease)

```

The SVM model can identify case samples but confuse some controls with case samples. The performance is still good for samples with variants.

```{r}
svm_dnn1_dense1b <- trainSVM(set = discov_dnn1_dense1, feats = rownames(dnn1_dense1_se)[!apply(dnn1_dense1, 2, function(x) all(x == 0))])

pred_dnn1_dense1b <- predict(svm_dnn1_dense1b, t(assay(dnn1_dense1_se)))
table(pred_dnn1_dense1b, se$disease)
```

When using all the features with values different than 0, we are able to classify half of the case samples.`

Summary: The dense 1 layer still contains some information to differentiate cases and controls.

## Dense layer 2 output

### General pattern

We evaluated whether the output of the dense 2 layer still contained signal to differentiate the individuals by disease.

```{r}
dnn1_dense2 <- read_delim("../results/GSE97362_DNN/2021-11-16/model_features/v1/dense_1.tsv", delim = "\t")
dnn1_dense2 <- data.matrix(dnn1_dense2)

dnn1_dense2_se <- SummarizedExperiment(t(dnn1_dense2), colData = colData(se))
rownames(dnn1_dense2_se) <- paste0("Features", seq_len(nrow(dnn1_dense2_se)))

discov_dnn1_dense2 <- dnn1_dense2_se[, ! dnn1_dense2_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
valid_dnn1_dense2 <- dnn1_dense2_se[, dnn1_dense2_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
```

We obtained `r nrow(dnn1_dense2_se)` features from the dense layer. Of those, `r sum(!apply(dnn1_dense2, 2, function(x) all(x == 0)))` had values different than 0 in at least a sample.

```{r}
pc_dnn1_dense2 <- prcomp(dnn1_dense2)$x %>%
  data.frame()
rownames(pc_dnn1_dense2) <- colnames(dnn1_dense2_se)
pc_dnn1_dense2$disease <- colData(se)[rownames(pc_dnn1_dense2), "disease"]
pc_dnn1_dense2$sex <- colData(se)[rownames(pc_dnn1_dense2), "sex"]
```

```{r}
pc_dnn1_dense2 %>% 
  ggplot(aes(x = PC1, y = PC2, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("DNN1 model dense2 features - Disease")
```

The second top PC of dense 2 features from DNN model separates charge from controls.

```{r}
pc_dnn1_dense2 %>% 
  ggplot(aes(x = PC2, y = PC3, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("DNN1 model dense2 features - Disease")
```

Components PC2 and PC3 of features from DNN model dense2 cluster samples by disease type. Nonetheless, the clustering was better when using the all the CpGs.

```{r}
pc_dnn1_dense2 %>% 
  ggplot(aes(x = PC1, y = PC2, color = sex)) +
  geom_point() + 
  theme_bw() +
  ggtitle("DNN1 model dense2 features - Disease")
```

The first component is not separating sample by sex. 

Summary: the features computed by the DNN model dense1 layer are capturing the difference in methylation due to disease rather than to sex.

### Heatmaps

We will select only those features where at least one sample has a values different than 0.

```{r}
sel_dnn1_dense2_vec <- rownames(discov_dnn1_dense2)[!apply(dnn1_dense2, 2, function(x) all(x == 0))]
```


```{r}
pheatmap(assay(discov_dnn1_dense2)[sel_dnn1_dense2_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(discov_dnn1_dense2)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

There are some cluster of case samples but they are not separated from controls.
```{r}
pheatmap(assay(valid_dnn1_dense2)[sel_dnn1_dense2_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(valid_dnn1_dense2)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

Some samples with variants are separated from controls..

### SVM model

We repeated the SVM with all the features from dense 2 different than 0.

```{r}
svm_dnn1_dense2 <- trainSVM(set = discov_dnn1_dense2, feats = sel_dnn1_dense2_vec)

pred_dnn1_dense2 <- predict(svm_dnn1_dense2, t(assay(dnn1_dense2_se)))
table(pred_dnn1_dense2, se$disease)

```

The predicition is very poor. It only worked for some CHARGE samples. 

Summary: The dense 2 layer still contain some information to differentiate cases and controls, although it might not be enough for correctly distinguish the individuals.

# CNN+auto model

## Description

After we trained the CNN model, we trained an autoencoder based on the output of the CNN layers. This autoencoder had the same dimensions than the layers of the full CNN model. After it was trained, we changed the weights of the CNN model with the weights of the autoencoder. We trained the resulting model for one epoch to maximize the accuracy.

## CNN layer

### General pattern

As we retrain for one epoch the model after changing the layers included in the autoencoder, we checked that the CNN features selected in the previous step still capture the signal.

```{r}
cnnauto_cnn <- read_delim("../results/GSE97632/2021-11-05/model_features/CNN_autoencod_train_v1/flatten.tsv", delim = "\t")
cnnauto_cnn <- data.matrix(cnnauto_cnn)

cnnauto_cnn_se <- SummarizedExperiment(t(cnnauto_cnn), colData = colData(se))
rownames(cnnauto_cnn_se) <- paste0("Features", seq_len(nrow(cnnauto_cnn_se)))

discov_cnnauto_cnn <- cnnauto_cnn_se[, ! cnnauto_cnn_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
valid_cnnauto_cnn <- cnnauto_cnn_se[, cnnauto_cnn_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
```

We obtained `r nrow(cnnauto_cnn_se)` features from the CNN layer. Of those, `r sum(!apply(cnnauto_cnn, 2, function(x) all(x == 0)))` had values different than 0 in at least a sample.

```{r}
pc_cnnauto_cnn <- prcomp(cnnauto_cnn)$x %>%
  data.frame()
rownames(pc_cnnauto_cnn) <- colnames(cnnauto_cnn_se)
pc_cnnauto_cnn$disease <- colData(se)[rownames(pc_cnnauto_cnn), "disease"]
pc_cnnauto_cnn$sex <- colData(se)[rownames(pc_cnnauto_cnn), "sex"]
```

```{r}
pc_cnnauto_cnn %>% 
  ggplot(aes(x = PC1, y = PC2, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("CNN+auto model CNN features - Disease")
```

The top 2 PCs of CNN features from CNN model does not allow differentiating the cases from the the control individuals.

```{r}
pc_cnnauto_cnn %>% 
  ggplot(aes(x = PC6, y = PC10, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("CNN+auto model CNN features - Disease")
```

Components PC6 and PC10 of CNN features from CNN+auto model cluster samples by disease type. Nonetheless, the clustering was better when using the full dataset.

```{r}
pc_cnnauto_cnn %>% 
  ggplot(aes(x = PC1, y = PC2, color = sex)) +
  geom_point() + 
  theme_bw() +
  ggtitle("CNN+auto model CNN features - Sex")
```

The first component clearly cluster samples by sex.

Summary: the features from CNN layer of CNN+auto model are mostly equivalent to those of CNN model.

### Features previously selected

```{r}
pheatmap(assay(discov_cnnauto_cnn)[sel_cnn_cnn_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(discov_cnnauto_cnn)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

Kabuki and control samples are clearly separated. Nonetheless, the differences between CHARGE and control are not so strong than when using all the CpGs.

```{r}
pheatmap(assay(valid_cnnauto_cnn)[sel_cnn_cnn_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(valid_cnnauto_cnn)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)
```

We observed clusters of individuals with suspicious variants but no clear differences between cases and controls are observed.

### SVM training

We used the same features selected for the CNN model.

```{r}
svm_cnnauto_cnn <- trainSVM(set = discov_cnnauto_cnn, feats = sel_cnn_cnn_vec)

pred_cnnauto_cnn <- predict(svm_cnnauto_cnn, t(assay(cnnauto_cnn_se)))
table(pred_cnnauto_cnn, se$disease)

```

The SVM model presented a lower accuracy than when using the CNN layer of the CNN model. The performance was worse for training samples, which presented a higher number of controls identified as cases.

### SVM training with newly selected features

```{r}
sel_cnnauto_cnn <- lapply(diseases, getFeatures, set = discov_cnnauto_cnn, minFC = 0.05)
sel_cnnauto_cnn_vec <- unique(unlist(sel_cnnauto_cnn))

svm_cnnauto_cnn2 <- trainSVM(set = discov_cnnauto_cnn, feats = sel_cnnauto_cnn_vec)

pred_cnnauto_cnn2 <- predict(svm_cnnauto_cnn2, t(assay(cnnauto_cnn_se)))
table(pred_cnnauto_cnn2, se$disease)

```

After repeating the features selection on this CNN features from CNN+auto model, the performance of the SVM is improved, but still it is worse than when using the CNN features from CNN model.

Summary: The extra training epoch seem to have changed the features previously obtained, so they have a worse classification.

## Dense layer 1 output

### General pattern

We first evaluated whether the output of the dense 1 layer still contained signal to differentiate the individuals by disease.

```{r}
cnnauto_dense1 <- read_delim("../results/GSE97632/2021-11-05/model_features/CNN_autoencod_train_v1/dense.tsv", delim = "\t")
cnnauto_dense1 <- data.matrix(cnnauto_dense1)

cnnauto_dense1_se <- SummarizedExperiment(t(cnnauto_dense1), colData = colData(se))
rownames(cnnauto_dense1_se) <- paste0("Features", seq_len(nrow(cnnauto_dense1_se)))

discov_cnnauto_dense1 <- cnnauto_dense1_se[, ! cnnauto_dense1_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
valid_cnnauto_dense1 <- cnnauto_dense1_se[, cnnauto_dense1_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
```

We obtained `r nrow(cnnauto_dense1_se)` features from the dense layer. Of those, `r sum(!apply(cnnauto_dense1, 2, function(x) all(x == 0)))` had values different than 0 in at least a sample.

```{r}
pc_cnnauto_dense1 <- prcomp(cnnauto_dense1)$x %>%
  data.frame()
rownames(pc_cnnauto_dense1) <- colnames(cnnauto_dense1_se)
pc_cnnauto_dense1$disease <- colData(se)[rownames(pc_cnnauto_dense1), "disease"]
pc_cnnauto_dense1$sex <- colData(se)[rownames(pc_cnnauto_dense1), "sex"]
```

```{r}
pc_cnnauto_dense1 %>% 
  ggplot(aes(x = PC1, y = PC2, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("CNN+auto model dense1 features - Disease")
```

The top 2 PCs of dense 1 features from CNN+auto model does not allow differentiating the cases from the the control individuals.

```{r}
pc_cnnauto_dense1 %>% 
  ggplot(aes(x = PC6, y = PC10, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("CNN+auto model dense1 features - Disease")
```

Components PC6 and PC10 of features from CNN+auto model dense1 layer cluster samples by disease type. Nonetheless, the clustering was better when using the all the CpGs or the CNN features.

```{r}
pc_cnnauto_dense1 %>% 
  ggplot(aes(x = PC1, y = PC2, color = sex)) +
  geom_point() + 
  theme_bw() +
  ggtitle("CNN+auto model dense1 features - Sex")
```

The second component clearly cluster samples by sex.

Summary: the features computed by the CNN+auto model dense1 layer are capturing the difference in methylation due to sex, while the differences due to the disease are not well captured.

### Features selection

Due to the high number of features without significant values, we remove them before selecting the features.

```{r}
sel_cnnauto_dense1 <- lapply(diseases, getFeatures, set = discov_cnnauto_dense1[!apply(cnnauto_dense1, 2, function(x) all(x == 0)), ], minFC = 0)
sel_cnnauto_dense1_vec <- unique(unlist(sel_cnnauto_dense1))
```

A total of `r length(sel_cnnauto_dense1$CHARGE)` and `r length(sel_cnnauto_dense1$Kabuki)` features had different methylation values in controls than in CHARGE or Kabuki, respectively.

```{r}
pheatmap(assay(discov_cnnauto_dense1)[sel_cnnauto_dense1_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(discov_cnnauto_dense1)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

We observed some difference between cases and controls that are more evident for Kabuki than for CHARGE.

```{r}
pheatmap(assay(valid_cnnauto_dense1)[sel_cnnauto_dense1_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(valid_cnnauto_dense1)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

These features do not work better in the samples with variants.

### SVM model

We repeated the SVM with the features selected in the previous step.

```{r}
svm_cnnauto_dense1 <- trainSVM(set = discov_cnnauto_dense1, feats = sel_cnnauto_dense1_vec)

pred_cnnauto_dense1 <- predict(svm_cnnauto_dense1, t(assay(cnnauto_dense1_se)))
table(pred_cnnauto_dense1, se$disease)

```

The performance is similar to when using the features of CNN model dense1 layer, but worse in this case. The number of controls missclassified has increased (46 vs 44) and fewer individuals with variants are identified as their disease (12 vs 17).

Summary: The dense1 from the autoencoder does not contain more information to differentiate cases and controls than when running the CNN model.

## Dense layer 2 output

### General pattern

We evaluated whether the output of the dense 2 layer still contained signal to differentiate the individuals by disease.

```{r}
cnnauto_dense2 <- read_delim("../results/GSE97632/2021-11-05/model_features/CNN_autoencod_train_v1/dense_1.tsv", delim = "\t")
cnnauto_dense2 <- data.matrix(cnnauto_dense2)

cnnauto_dense2_se <- SummarizedExperiment(t(cnnauto_dense2), colData = colData(se))
rownames(cnnauto_dense2_se) <- paste0("Features", seq_len(nrow(cnnauto_dense2_se)))

discov_cnnauto_dense2 <- cnnauto_dense2_se[, ! cnnauto_dense2_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
valid_cnnauto_dense2 <- cnnauto_dense2_se[, cnnauto_dense2_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
```

We obtained `r nrow(cnnauto_dense2_se)` features from the dense layer. Of those, `r sum(!apply(cnnauto_dense2, 2, function(x) all(x == 0)))` had values different than 0 in at least a sample.

```{r}
pc_cnnauto_dense2 <- prcomp(cnnauto_dense2)$x %>%
  data.frame()
rownames(pc_cnnauto_dense2) <- colnames(cnnauto_dense2_se)
pc_cnnauto_dense2$disease <- colData(se)[rownames(pc_cnnauto_dense2), "disease"]
pc_cnnauto_dense2$sex <- colData(se)[rownames(pc_cnnauto_dense2), "sex"]
```

```{r}
pc_cnnauto_dense2 %>% 
  ggplot(aes(x = PC1, y = PC2, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("CNN+auto model dense2 features - Disease")
```

The top 2 PCs of dense 2 features from CNN model does not allow differentiating the cases from the the control individuals.

```{r}
pc_cnnauto_dense2 %>% 
  ggplot(aes(x = PC5, y = PC6, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("CNN model dense2 features - Disease")
```

Components PC5 and PC6 of features from CNN+auto model dense2 layer cluster samples by disease type. Nonetheless, the clustering was better when using the all the CpGs or the CNN features.

```{r}
pc_cnnauto_dense2 %>% 
  ggplot(aes(x = PC1, y = PC2, color = sex)) +
  geom_point() + 
  theme_bw() +
  ggtitle("CNN+auto model dense2 features - Sex")
```

Again, the second component clearly cluster samples by sex, though the difference is not as strong.

Summary: the features computed by the CNN+auto model dense2 layer are quite similar than the features from CNN model dense2 layer

### Features selection

Due to the high number of features without significant values, we remove them before selecting the features.

```{r}
sel_cnnauto_dense2 <- lapply(diseases, getFeatures, set = discov_cnnauto_dense2[!apply(cnnauto_dense2, 2, function(x) all(x == 0)), ], minFC = 0)
sel_cnnauto_dense2_vec <- unique(unlist(sel_cnnauto_dense2))
```

No features had differences between cases and controls.

```{r}
pheatmap(assay(discov_cnn_dense2)[!apply(cnnauto_dense2, 2, function(x) all(x == 0)), ], scale = "none", 
         annotation_col  = data.frame(colData(discov_cnn_dense2)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

Samples are clustered by sex, although different sub-groups are observed. Then, we observed some clustering of Kabuki samples.

```{r}
pheatmap(assay(valid_cnnauto_dense2)[!apply(cnnauto_dense2, 2, function(x) all(x == 0)), ], scale = "none", 
         annotation_col  = data.frame(colData(valid_cnnauto_dense2)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

Samples are clustered by sex. For females, we observed a clustering of case samples, but with both diseases merged.

### SVM model

We repeated the SVM with all the features from dense 2 different than 0.

```{r}
svm_cnnauto_dense2 <- trainSVM(set = discov_cnnauto_dense2, feats = rownames(cnnauto_dense2_se)[!apply(cnnauto_dense2, 2, function(x) all(x == 0))])

pred_cnnauto_dense2 <- predict(svm_cnnauto_dense2, t(assay(cnnauto_dense2_se)))
table(pred_cnnauto_dense2, se$disease)

```

The SVM had a very bad performance, classifying all samples as control. This performance is much worse than for CNN model.

# auto model

## Description

We repeated the exploration of the features but without retraining the network after adding the weights of the autoencoder.

## Dense layer 1 output

### General pattern

We first evaluated whether the output of the dense 1 layer still contained signal to differentiate the individuals by disease.

```{r}
auto_dense1 <- read_delim("../results/GSE97632/2021-11-05/model_features/autoencoder_dense.tsv", delim = "\t")
auto_dense1 <- data.matrix(auto_dense1)

auto_dense1_se <- SummarizedExperiment(t(auto_dense1), colData = colData(se))
rownames(auto_dense1_se) <- paste0("Features", seq_len(nrow(auto_dense1_se)))

discov_auto_dense1 <- auto_dense1_se[, ! auto_dense1_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
valid_auto_dense1 <- auto_dense1_se[, auto_dense1_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
```

We obtained `r nrow(auto_dense1_se)` features from the dense layer. Of those, `r sum(!apply(auto_dense1, 2, function(x) all(x == 0)))` had values different than 0 in at least a sample.

```{r}
pc_auto_dense1 <- prcomp(auto_dense1)$x %>%
  data.frame()
rownames(pc_auto_dense1) <- colnames(auto_dense1_se)
pc_auto_dense1$disease <- colData(se)[rownames(pc_auto_dense1), "disease"]
pc_auto_dense1$sex <- colData(se)[rownames(pc_auto_dense1), "sex"]
```

```{r}
pc_auto_dense1 %>% 
  ggplot(aes(x = PC1, y = PC2, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("auto model dense1 features - Disease")
```

The top 2 PCs of dense 1 features from auto model does not allow differentiating the cases from the the control individuals.

```{r}
pc_auto_dense1 %>% 
  ggplot(aes(x = PC5, y = PC10, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("auto model dense1 features - Disease")
```

Components PC5 and PC10 of features from uto model dense1 layer cluster samples by disease type. 

```{r}
pc_auto_dense1 %>% 
  ggplot(aes(x = PC1, y = PC2, color = sex)) +
  geom_point() + 
  theme_bw() +
  ggtitle("auto model dense1 features - Sex")
```

The second component clearly cluster samples by sex.

Summary: the features computed by the auto model dense1 layer are similar than those from CNN model. 

### Features selection

Due to the high number of features without significant values, we remove them before selecting the features.

```{r}
sel_auto_dense1 <- lapply(diseases, getFeatures, set = discov_auto_dense1[!apply(auto_dense1, 2, function(x) all(x == 0)), ], minFC = 0)
sel_auto_dense1_vec <- unique(unlist(sel_auto_dense1))
```

A total of `r length(sel_auto_dense1$CHARGE)` and `r length(sel_auto_dense1$Kabuki)` features had different methylation values in controls than in CHARGE or Kabuki, respectively.

```{r}
pheatmap(assay(discov_auto_dense1)[sel_auto_dense1_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(discov_auto_dense1)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

We observed some difference between cases and controls that are more evident for Kabuki than for CHARGE.

```{r}
pheatmap(assay(valid_auto_dense1)[sel_auto_dense1_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(valid_auto_dense1)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

Apparently, the features from auto model works better than those of CNN model.

### SVM model

We repeated the SVM with the features selected in the previous step.

```{r}
svm_auto_dense1 <- trainSVM(set = discov_auto_dense1, feats = sel_auto_dense1_vec)

pred_auto_dense1 <- predict(svm_auto_dense1, t(assay(auto_dense1_se)))
table(pred_auto_dense1, se$disease)

```

The performance is similar to when using the features of CNN model dense1 layer. The number of controls missclassified has increased (46 vs 44), but one less CHARGE are identified as control. The same number of individuals with variants are identified as their disease (17).

Summary: The dense1 from the autoencoder has similar information to differentiate cases and controls than when running the CNN model.

## Dense layer 2 output

### General pattern

We evaluated whether the output of the dense 2 layer still contained signal to differentiate the individuals by disease.

```{r}
auto_dense2 <- read_delim("../results/GSE97632/2021-11-05/model_features/autoencoder_dense1.tsv", delim = "\t")
auto_dense2 <- data.matrix(auto_dense2)

auto_dense2_se <- SummarizedExperiment(t(auto_dense2), colData = colData(se))
rownames(auto_dense2_se) <- paste0("Features", seq_len(nrow(auto_dense2_se)))

discov_auto_dense2 <- auto_dense2_se[, ! auto_dense2_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
valid_auto_dense2 <- auto_dense2_se[, auto_dense2_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
```

We obtained `r nrow(auto_dense2_se)` features from the dense layer. Of those, `r sum(!apply(auto_dense2, 2, function(x) all(x == 0)))` had values different than 0 in at least a sample.

```{r}
pc_auto_dense2 <- prcomp(auto_dense2)$x %>%
  data.frame()
rownames(pc_auto_dense2) <- colnames(auto_dense2_se)
pc_auto_dense2$disease <- colData(se)[rownames(pc_auto_dense2), "disease"]
pc_auto_dense2$sex <- colData(se)[rownames(pc_auto_dense2), "sex"]
```

```{r}
pc_auto_dense2 %>% 
  ggplot(aes(x = PC1, y = PC2, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("auto model dense2 features - Disease")
```

The top 2 PCs of dense 2 features from CNN model does not allow differentiating the cases from the the control individuals.

```{r}
pc_auto_dense2 %>% 
  ggplot(aes(x = PC5, y = PC8, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("Auto model dense2 features - Disease")
```

Components PC5 and PC8 of features from auto model dense2 layer cluster samples by disease type. Nonetheless, the clustering was better when using the all the CpGs or the CNN features.

```{r}
pc_auto_dense2 %>% 
  ggplot(aes(x = PC1, y = PC2, color = sex)) +
  geom_point() + 
  theme_bw() +
  ggtitle("CNN+auto model dense2 features - Sex")
```

Again, the first component clearly cluster samples by sex, though the difference is not as strong.

Summary: the features computed by the auto model dense2 layer are quite similar than the features from CNN model dense2 layer

### Features selection

Due to the high number of features without significant values, we remove them before selecting the features.

```{r}
sel_auto_dense2 <- lapply(diseases, getFeatures, set = discov_auto_dense2[!apply(auto_dense2, 2, function(x) all(x == 0)), ], minFC = 0)
sel_auto_dense2_vec <- unique(unlist(sel_auto_dense2))
```

No features had differences between cases and controls.

```{r}
pheatmap(assay(discov_cnn_dense2)[!apply(auto_dense2, 2, function(x) all(x == 0)), ], scale = "none", 
         annotation_col  = data.frame(colData(discov_cnn_dense2)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

Samples are clustered by sex, although different sub-groups are observed. Then, we observed some clustering of Kabuki samples.

```{r}
pheatmap(assay(valid_auto_dense2)[!apply(auto_dense2, 2, function(x) all(x == 0)), ], scale = "none", 
         annotation_col  = data.frame(colData(valid_auto_dense2)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

Samples are clustered by sex. For females, we observed a clustering of case samples, but with both diseases merged.

### SVM model

We repeated the SVM with all the features from dense 2 different than 0.

```{r}
svm_auto_dense2 <- trainSVM(set = discov_auto_dense2, feats = rownames(auto_dense2_se)[!apply(auto_dense2, 2, function(x) all(x == 0))])

pred_auto_dense2 <- predict(svm_auto_dense2, t(assay(auto_dense2_se)))
table(pred_auto_dense2, se$disease)

```

The SVM cannot differentiate any case from controls. 

## Autoencoder output layer

### General pattern

We checked that the output of the autoencoder still capture the signal.

```{r}
auto_out <- read_delim("../results/GSE97632/2021-11-05/model_features/autoencoder_output.tsv", delim = "\t")
auto_out <- data.matrix(auto_out)

auto_out_se <- SummarizedExperiment(t(auto_out), colData = colData(se))
rownames(auto_out_se) <- paste0("Features", seq_len(nrow(auto_out_se)))

discov_auto_out <- auto_out_se[, ! auto_out_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
valid_auto_out <- auto_out_se[, auto_out_se$`sample type:ch1`  %in% c("Control for validation cohort",  "Validation cohort") ]
```

We obtained `r nrow(auto_out_se)` features from the CNN layer. Of those, `r sum(!apply(auto_out, 2, function(x) all(x == 0)))` had values different than 0 in at least a sample.

```{r}
pc_auto_out <- prcomp(auto_out)$x %>%
  data.frame()
rownames(pc_auto_out) <- colnames(auto_out_se)
pc_auto_out$disease <- colData(se)[rownames(pc_auto_out), "disease"]
pc_auto_out$sex <- colData(se)[rownames(pc_auto_out), "sex"]
```

```{r}
pc_auto_out %>% 
  ggplot(aes(x = PC1, y = PC2, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("autoencoder output - Disease")
```

The top 2 PCs of CNN features from CNN model does not allow differentiating the cases from the the control individuals.

```{r}
pc_auto_out %>% 
  ggplot(aes(x = PC5, y = PC9, color = disease)) +
  geom_point() + 
  theme_bw() +
  ggtitle("autoencoder output - Disease")
```

It is very hard to differentiate the individuals by disease with the PCs based on the autoencoder output.

```{r}
pc_auto_out %>% 
  ggplot(aes(x = PC1, y = PC2, color = sex)) +
  geom_point() + 
  theme_bw() +
  ggtitle("Autoencoder output - Sex")
```

The first two components clearly cluster samples by sex.

Summary: the signal of the disease is lost after applying the autoencoder. 

### Features previously selected

```{r}
pheatmap(assay(discov_auto_out)[sel_cnn_cnn_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(discov_auto_out)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)

```

Samples are separated by sex, not by disease.

```{r}
pheatmap(assay(valid_auto_out)[sel_cnn_cnn_vec, ], scale = "none", 
         annotation_col  = data.frame(colData(valid_auto_out)[, c("disease", "sex"), drop = FALSE]),
         annotation_colors =  col_colors, 
         show_rownames = FALSE)
```

Samples are separeted by sex, not by disease.

### SVM training

We used the same features selected for the CNN model.

```{r}
svm_auto_out <- trainSVM(set = discov_auto_out, feats = sel_cnn_cnn_vec)

pred_auto_out <- predict(svm_auto_out, t(assay(auto_out_se)))
table(pred_auto_out, se$disease)

```

Using the previously selected features, the SVM is not able to differentiate any of the cases from the controls.

### SVM training with newly selected features

```{r}
sel_auto_out <- lapply(diseases, getFeatures, set = discov_auto_out, minFC = 0.05)
sel_auto_out

```

No features are associated with the diseases form the output of the autoencoder.

Summary: The autoencoder is not recapitulating the signal regarding the disease.

# Summary

The autoencoder is not recapitulating the signal regarding the disease. Thus, we are not improving the results by adding this step.